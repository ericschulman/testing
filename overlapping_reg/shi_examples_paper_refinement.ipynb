{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import vuong_tests_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS_loglike(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, *args,ols=False, **kwargs):\n",
    "        super(OLS_loglike,self).__init__(*args,**kwargs)\n",
    "        self.ols = ols\n",
    "\n",
    "    def loglikeobs(self, params):\n",
    "        y = self.endog\n",
    "        x = self.exog\n",
    "        mu_y = np.matmul(x,params)  \n",
    "        resid = y - mu_y\n",
    "        sigma = np.sqrt(np.sum(resid**2)/resid.shape[0])\n",
    "        pr_y = stats.norm.logpdf( resid, loc=0,scale=sigma )\n",
    "        return pr_y\n",
    "\n",
    "\n",
    "def setup_shi(yn,xn,return_model=False,num_params=4):\n",
    "    x1n,x2n = xn[:,0],xn[:,1:num_params+1]\n",
    "    \n",
    "    # model 1 grad, etc.\n",
    "    model1 = sm.OLS(yn,sm.add_constant(x1n))\n",
    "    model1_fit = model1.fit(disp=False)\n",
    "    params1 = (model1_fit.params)\n",
    "    \n",
    "    model1_deriv = OLS_loglike(yn,sm.add_constant(x1n))\n",
    "    ll1 = model1_deriv.loglikeobs(model1_fit.params)\n",
    "    grad1 =  model1_deriv.score_obs(model1_fit.params)    \n",
    "    hess1 = model1_deriv.hessian(model1_fit.params)\n",
    "    \n",
    "    #model 2 grad, etc.\n",
    "    model2 = sm.OLS(yn,sm.add_constant(x2n))\n",
    "    model2_fit = model2.fit(disp=False)\n",
    "    params2 = (model2_fit.params)\n",
    "    \n",
    "    model2_deriv = OLS_loglike(yn,sm.add_constant(x2n))\n",
    "    ll2 = model2_deriv.loglikeobs(model2_fit.params)\n",
    "    grad2 =  model2_deriv.score_obs(model2_fit.params)    \n",
    "    hess2 = model2_deriv.hessian(model2_fit.params)\n",
    "    \n",
    "    if return_model:\n",
    "        return ll1,grad1,hess1,params1,model1,ll2,grad2,hess2,params2,model2\n",
    "    return ll1,grad1,hess1,params1,ll2,grad2,hess2,params2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "def gen_data(nobs=1000, a=0.25, num_params=4):\n",
    "    x = np.random.normal(scale=1., size=(nobs,1+num_params))\n",
    "    e = np.random.normal(loc=0.0, scale=1.0, size=nobs)\n",
    "    y = 1 + a*x[:,0] + a/np.sqrt(num_params)*x[:,1:num_params+1].sum(axis=1) + e\n",
    "    return y,x,nobs\n",
    "\n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn,return_model=False,num_params=15)\n",
    "print(grad1.shape,hess1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 5\n",
    "trials =1000\n",
    "\n",
    "skip_shi = True\n",
    "refinement_test=True\n",
    "adapt_c = False\n",
    "\n",
    "calc_c =lambda nobs: (1.25*nobs**(1/4)/np.sqrt(nobs), .75*nobs**(1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cccc}\n",
      "\\hline\n",
      "\\textbf{$\\alpha$} & {} & \\textbf{No selection} & \\textbf{Model 1} & \\textbf{Model 2} \\\\\n",
      "\\hline\n",
      "{$0.01$} & \\textbf{Normal} & 0.98 & 0.02 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.92 & 0.08 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.05$} & \\textbf{Normal} & 0.86 & 0.14 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.66 & 0.34 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.10$} & \\textbf{Normal} & 0.66 & 0.34 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.50 & 0.50 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.15$} & \\textbf{Normal} & 0.54 & 0.46 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.41 & 0.59 & 0.00 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# Input arrays\n",
    "alpha = [0.01, 0.05, 0.10, 0.15]\n",
    "results = np.array([\n",
    "    [[0.98, 0.02, 0.00], [0.92, 0.08, 0.00]],\n",
    "    [[0.86, 0.14, 0.00], [0.66, 0.34, 0.00]],\n",
    "    [[0.66, 0.34, 0.00], [0.50, 0.50, 0.00]],\n",
    "    [[0.54, 0.46, 0.00], [0.41, 0.59, 0.00]]\n",
    "])\n",
    "# Column headers\n",
    "\n",
    "def print_mc2(alpha_levels ,test_results ):\n",
    "    table = \"\\\\begin{tabular}{c|cccc}\\n\"\n",
    "    table += \"\\\\hline\\n\"\n",
    "    table += \"\\\\textbf{$\\\\alpha$} & {} & \\\\textbf{No selection} & \\\\textbf{Model 1} & \\\\textbf{Model 2} \\\\\\\\\\n\"\n",
    "    table += \"\\\\hline\\n\"\n",
    "\n",
    "    for i in range(len(alpha_levels)):\n",
    "        alpha = alpha_levels[i]\n",
    "        table += \"{$%.2f$} & \\\\textbf{Normal} & %.2f & %.2f & %.2f \\\\\\\\\\n\" % (alpha, test_results[i][0][0], test_results[i][0][1], test_results[i][0][2])\n",
    "        table += \"& \\\\textbf{Bootstrap-ND} & %.2f & %.2f & %.2f \\\\\\\\\\n\" % (test_results[i][1][0], test_results[i][1][1], test_results[i][1][2])\n",
    "        table += \"\\\\hline\\n\"\n",
    "\n",
    "    table += \"\\\\end{tabular}\"\n",
    "\n",
    "    print(table)\n",
    "\n",
    "print_mc2(alpha,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evidence of power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,a2 = np.sqrt(1.09-1), 0.00\n",
    "\n",
    "def gen_data2(nobs=1000, a1=np.sqrt(1.09-1), a2=0.00 , num_params=19):\n",
    "    x = np.random.normal(scale=1., size=(nobs,1+num_params))\n",
    "    e = np.random.normal(loc=0.0, scale=1.0, size=nobs)\n",
    "    y = 1 + a1*x[:,0] + a2/np.sqrt(num_params)*x[:,1:num_params+1].sum(axis=1) + e\n",
    "    return y,x,nobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4, n=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m setup_shi_ex  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m yn,xn: setup_shi(yn,xn,num_params\u001b[38;5;241m=\u001b[39mnum_params)\n\u001b[0;32m     10\u001b[0m gen_data_ex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m : gen_data2(nobs\u001b[38;5;241m=\u001b[39mnobs, a1\u001b[38;5;241m=\u001b[39ma1, a2\u001b[38;5;241m=\u001b[39ma2, num_params\u001b[38;5;241m=\u001b[39mnum_params)\n\u001b[1;32m---> 11\u001b[0m mc_out \u001b[38;5;241m=\u001b[39m \u001b[43mvuong_tests_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonte_carlo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_sims\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgen_data_ex\u001b[49m\u001b[43m,\u001b[49m\u001b[43msetup_shi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43madapt_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapt_c\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mskip_shi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_shi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefinement_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefinement_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega \u001b[38;5;241m=\u001b[39m mc_out\n\u001b[0;32m     14\u001b[0m test_results\u001b[38;5;241m.\u001b[39mappend([refine_test,boot3])\n",
      "File \u001b[1;32m~\\Documents\\testing\\overlapping_reg\\..\\vuong_tests_fast.py:104\u001b[0m, in \u001b[0;36mmonte_carlo\u001b[1;34m(total, gen_data, setup_shi, skip_boot, skip_shi, refinement_test, trials, biascorrect, c1, c2, alpha, adapt_c)\u001b[0m\n\u001b[0;32m    102\u001b[0m boot_index1,boot_index2,boot_index3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_boot:\n\u001b[1;32m--> 104\u001b[0m     test_stats1,test_stats2,test_stats3a,test_stats3b ,test_stat1,test_stat2,test_stat3 \u001b[38;5;241m=\u001b[39m \u001b[43mbootstrap_distr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mll1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrad1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhess1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mll2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgrad2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhess2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m#print('-- test1 --')\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     boot_index1 \u001b[38;5;241m=\u001b[39m bootstrap_test(test_stats1,test_stat1,alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[1;32m~\\Documents\\testing\\overlapping_reg\\..\\vuong_tests_fast.py:32\u001b[0m, in \u001b[0;36mbootstrap_distr\u001b[1;34m(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, c1, c2, trials, alpha)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(trials):\n\u001b[0;32m     31\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed()\n\u001b[1;32m---> 32\u001b[0m     sample  \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     llrs \u001b[38;5;241m=\u001b[39m llr[sample]\n\u001b[0;32m     34\u001b[0m     test_stats\u001b[38;5;241m.\u001b[39mappend( llrs\u001b[38;5;241m.\u001b[39msum() )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_params=4\n",
    "nobs=250\n",
    "a1,a2 = np.sqrt(1.09-1), 0.00\n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data2(nobs=nobs, a1=a1, a2=a2, num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([refine_test,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4,n=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params=4\n",
    "nobs=500\n",
    "a1,a2 = np.sqrt(1.09-1), 0.00\n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data2(nobs=nobs, a1=a1, a2=a2, num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([refine_test,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# size stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4,n=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_params=4\n",
    "nobs=250\n",
    "a=.25 \n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data(nobs=nobs, a=a,  num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([refine_test,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4,n=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_params=4\n",
    "nobs=500\n",
    "a=.25 \n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data(nobs=nobs, a=a,  num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([refine_test,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
