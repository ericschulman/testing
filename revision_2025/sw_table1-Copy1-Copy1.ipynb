{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4477e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import vuong_tests11 as vuong_tests_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5668dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "class JointNormal1(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([params[0], 0.0], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "    \n",
    "    \n",
    "class JointNormal2(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([0.0, params[0]], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "\n",
    "\n",
    "def setup_shi(yn,xn):\n",
    "    # model 1 grad, etc.\n",
    "    nobs = yn.shape[0]\n",
    "    model1_param = np.array([yn.mean()])\n",
    "    model2_param = np.array([xn.mean()])\n",
    "    \n",
    "    model1_deriv = JointNormal1(yn,xn)\n",
    "    ll1 = model1_deriv.loglikeobs(model1_param)\n",
    "    grad1 =  model1_deriv.score_obs(model1_param).reshape( (nobs,1) )\n",
    "    hess1 = model1_deriv.hessian(model1_param)\n",
    "    \n",
    "    \n",
    "    model2_deriv = JointNormal2(yn,xn)\n",
    "    ll2 = model2_deriv.loglikeobs(model2_param)\n",
    "    grad2 =  model2_deriv.score_obs(model2_param).reshape( (nobs,1) )  \n",
    "    hess2 = model2_deriv.hessian(model2_param)\n",
    "    \n",
    "    return ll1,grad1,hess1,model1_param,ll2,grad2,hess2,model2_param\n",
    "\n",
    "def gen_data(beta= 1.5, nobs=1000):\n",
    "    cov = [[25, 0], [0, 1]]\n",
    "    data = np.random.multivariate_normal([beta,beta], [[25,0],[0,1]],  nobs)\n",
    "    return data[:,0],data[:,1],nobs\n",
    "\n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "print(grad1.shape,hess1.shape)\n",
    "#NOTE! Weird size distortions with shi's test when theta = .5...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0be3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 1000\n",
    "trials =1000\n",
    "adapt_c = True\n",
    "data_tuned_epsilon = True\n",
    "epsilon = .5\n",
    "biascorrect = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eda3e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_vector(mc_out):\n",
    "    \"\"\"\n",
    "    Returns the size (rejection probability under the null) for each method,\n",
    "    using your print order:\n",
    "      Normal, Two-Step, SW Test, Naive Bootstrap, Pairwise Bootstrap, Shi (2015)\n",
    "    \"\"\"\n",
    "    # Unpack\n",
    "    reg, twostep, sw, boot1, boot2, sw_test_opt, boot3, shi = mc_out[:8]\n",
    "    # Take 1 - (no selection rate)\n",
    "    size_vec = [\n",
    "        1 - reg[0],\n",
    "        1 - twostep[0],\n",
    "        1 - (sw_test_opt[0] if data_tuned_epsilon else sw[0]),\n",
    "        1 - boot1[0],\n",
    "        1 - (boot3[0] if data_tuned_epsilon else boot2[0]),   # boot3=Pairwise, boot1=Naive\n",
    "        1 - shi[0],\n",
    "    ]\n",
    "    return size_vec\n",
    "\n",
    "def run_null_size_table(sample_sizes, num_sims, trials, epsilon, data_tuned_epsilon, adapt_c,alpha=.05):\n",
    "    table = []\n",
    "    for nobs in sample_sizes:\n",
    "        setup_shi_ex = lambda yn,xn: setup_shi(yn,xn)\n",
    "        gen_data_ex = lambda : gen_data(nobs=nobs, beta=0)\n",
    "        mc_out = vuong_tests_fast.monte_carlo(\n",
    "            num_sims,\n",
    "            gen_data_ex,\n",
    "            setup_shi_ex,\n",
    "            trials=trials,\n",
    "            epsilon=epsilon,\n",
    "            data_tuned_epsilon = data_tuned_epsilon,\n",
    "            adapt_c = adapt_c,\n",
    "            print_stuff=False, alpha=alpha, biascorrect=biascorrect\n",
    "        )\n",
    "        size_vec = get_size_vector(mc_out)\n",
    "        table.append([nobs] + [f\"{x:.3f}\" for x in size_vec])\n",
    "    # Print as LaTeX table\n",
    "    print(r'\\begin{tabular}{|c|c|c|c|c|c|c|}')\n",
    "    print(r'\\hline')\n",
    "    print(r'Sample &  Normal & Two-Step & SW Test & Naive Bootstrap & Pairwise Bootstrap & Shi (2015) \\\\ \\hline \\hline')\n",
    "    for row in table:\n",
    "        print(' & '.join(str(y) for y in row)+r' \\\\')\n",
    "    print(r'\\hline')\n",
    "    print(r'\\end{tabular}')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105ca62",
   "metadata": {},
   "source": [
    "# original example from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec5f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your globals as needed\n",
    "sample_sizes = [100, 200, 500]\n",
    "table = run_null_size_table(\n",
    "    sample_sizes=sample_sizes,\n",
    "    num_sims=num_sims,                  # you set this already\n",
    "    trials=trials,                      # you set this already\n",
    "    epsilon=0.5,\n",
    "    data_tuned_epsilon=data_tuned_epsilon,\n",
    "    adapt_c=adapt_c\n",
    ")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd051bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your globals as needed\n",
    "table = run_null_size_table(\n",
    "    sample_sizes=sample_sizes,\n",
    "    num_sims=num_sims,                  # you set this already\n",
    "    trials=trials,                      # you set this already\n",
    "    epsilon=0.5,\n",
    "    data_tuned_epsilon=data_tuned_epsilon,\n",
    "    adapt_c=adapt_c,alpha=.025\n",
    ")\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your globals as needed\n",
    "table = run_null_size_table(\n",
    "    sample_sizes=sample_sizes,\n",
    "    num_sims=num_sims,                  # you set this already\n",
    "    trials=trials,                      # you set this already\n",
    "    epsilon=0.5,\n",
    "    data_tuned_epsilon=data_tuned_epsilon,\n",
    "    adapt_c=adapt_c,alpha=.01\n",
    ")\n",
    "\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
