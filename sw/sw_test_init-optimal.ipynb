{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import vuong_tests10 as vuong_tests_fast\n",
    "from vuong_test_base import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "class JointNormal1(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([params[0], 0.0], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "    \n",
    "    \n",
    "class JointNormal2(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([0.0, params[0]], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "\n",
    "\n",
    "def setup_shi(yn,xn):\n",
    "    # model 1 grad, etc.\n",
    "    nobs = yn.shape[0]\n",
    "    model1_param = np.array([yn.mean()])\n",
    "    model2_param = np.array([xn.mean()])\n",
    "    \n",
    "    model1_deriv = JointNormal1(yn,xn)\n",
    "    ll1 = model1_deriv.loglikeobs(model1_param)\n",
    "    grad1 =  model1_deriv.score_obs(model1_param).reshape( (nobs,1) )\n",
    "    hess1 = model1_deriv.hessian(model1_param)\n",
    "    \n",
    "    \n",
    "    model2_deriv = JointNormal2(yn,xn)\n",
    "    ll2 = model2_deriv.loglikeobs(model2_param)\n",
    "    grad2 =  model2_deriv.score_obs(model2_param).reshape( (nobs,1) )  \n",
    "    hess2 = model2_deriv.hessian(model2_param)\n",
    "    \n",
    "    return ll1,grad1,hess1,model1_param,ll2,grad2,hess2,model2_param\n",
    "\n",
    "def gen_data(beta= 1.5, nobs=1000):\n",
    "    cov = [[25, 0], [0, 1]]\n",
    "    data = np.random.multivariate_normal([beta,beta], [[25,0],[0,1]],  nobs)\n",
    "    return data[:,0],data[:,1],nobs\n",
    "\n",
    "\n",
    "def gen_data3(beta= 1.5, nobs=1000):\n",
    "    cov = [[25, 0], [0, 1]]\n",
    "    data = np.random.multivariate_normal([0,beta], [[25,0],[0,1]],  nobs)\n",
    "    return data[:,0],data[:,1],nobs\n",
    "\n",
    "\n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "print(grad1.shape,hess1.shape)\n",
    "#NOTE! Weird size distortions with shi's test when theta = .5...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Helper for \"sandwich\" variance components\n",
    "def _estimate_HV(grad, hess, ridge=1e-8):\n",
    "    n = grad.shape[0]\n",
    "    H_hat = -np.mean(hess, axis=0)\n",
    "    H_hat = H_hat + ridge * np.eye(H_hat.shape[0])\n",
    "    V_hat = (grad.T @ grad) / n\n",
    "    return H_hat, V_hat\n",
    "\n",
    "\n",
    "def _trace_HinvV(H, V):\n",
    "    X = np.linalg.solve(H, V)\n",
    "    return float(np.trace(X))\n",
    "\n",
    "\n",
    "def compute_optimal_epsilon(ll1, grad1, hess1, params1,\n",
    "                 ll2, grad2, hess2, params2, alpha=0.05, ridge=1e-8,\n",
    "                            min_epsilon=1e-6, max_epsilon=10.0):\n",
    "    nobs = ll1.shape[0]\n",
    "    idx_even = np.arange(0, nobs, 2)\n",
    "    idx_odd  = np.arange(1, nobs, 2)\n",
    "\n",
    "    # Variances\n",
    "    sigma2_hat  = float(np.var(ll1 - ll2, ddof=0))\n",
    "    sigmaA2_hat = float(np.var(ll1[idx_even], ddof=0)) if idx_even.size > 1 else 0.0\n",
    "    sigmaB2_hat = float(np.var(ll2[idx_odd],  ddof=0)) if idx_odd.size  > 1 else 0.0\n",
    "    sigma_hat   = np.sqrt(max(sigma2_hat, 1e-12))\n",
    "\n",
    "    # Estimate (H, V) for each model\n",
    "    H1_hat, V1_hat = _estimate_HV(grad1, hess1, ridge=ridge)\n",
    "    H2_hat, V2_hat = _estimate_HV(grad2, hess2, ridge=ridge)\n",
    "    try:\n",
    "        tr1 = abs(_trace_HinvV(H1_hat, V1_hat))\n",
    "        tr2 = abs(_trace_HinvV(H2_hat, V2_hat))\n",
    "        tr_max = max(tr1, tr2)\n",
    "    except np.linalg.LinAlgError:\n",
    "        tr_max = 1.0\n",
    "\n",
    "    # Paper constants\n",
    "    z = norm.ppf(1 - alpha/2.0)\n",
    "    phi_z = norm.pdf(z)\n",
    "    delta_star_hat = (sigma_hat / 2.0) * (z - np.sqrt(4.0 + z**2))\n",
    "    phi_arg = z - (delta_star_hat / max(sigma_hat, 1e-12))\n",
    "    phi_term = norm.pdf(phi_arg)\n",
    "\n",
    "    denom_PL = 4.0 * (sigma_hat**3 + 1e-24)\n",
    "    CPL_num = delta_star_hat * (sigma_hat**2 - 2.0 * (sigmaA2_hat + sigmaB2_hat))\n",
    "    C_PL_hat = phi_term * CPL_num / denom_PL\n",
    "\n",
    "    denom_SD = np.sqrt(max((sigmaA2_hat + sigmaB2_hat)/2.0, 1e-24))\n",
    "    C_SD_hat = 2.0 * phi_z * tr_max / denom_SD\n",
    "\n",
    "    lnln_term = max(np.log(np.log(max(nobs, 3))), 1e-6)\n",
    "    fallback = nobs**(-1/6) * (lnln_term**(1/3))\n",
    "\n",
    "    valid = (np.isfinite(C_PL_hat) and np.isfinite(C_SD_hat) and\n",
    "             C_PL_hat > 0 and C_SD_hat > 0)\n",
    "\n",
    "    if valid:\n",
    "        eps_hat = ((C_SD_hat/C_PL_hat)**(1/3)) * (nobs**(-1/6)) * (lnln_term**(1/3))\n",
    "    else:\n",
    "        eps_hat = fallback\n",
    "\n",
    "    return float(np.clip(eps_hat, min_epsilon, max_epsilon))\n",
    "\n",
    "def sw_test_stat(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=.5,compute_v=True,print_stuff=False):\n",
    "    nobs = ll1.shape[0]\n",
    "\n",
    "    idx_even = np.arange(0, nobs, 2)         # 0-based indices: 0,2,4,...\n",
    "    idx_odd  = np.arange(1, nobs, 2)         # 1,3,5,...\n",
    "\n",
    "    # Regular loglikelihood ratio statistic\n",
    "    llr = (ll1 - ll2).sum()\n",
    "    # Split-sample difference statistic\n",
    "    llr_split = ll1[idx_even].sum() - ll2[idx_odd].sum()\n",
    "    # Regularized numerator (as in your expression)\n",
    "    llr_reg = llr + epsilon * llr_split\n",
    "    # Main variance\n",
    "    omega2 = (ll1 - ll2).var()\n",
    "    # Split-group variances\n",
    "    omega_A2 = ll1[idx_even].var()\n",
    "    omega_B2 = ll2[idx_odd].var()\n",
    "    # Regularized variance\n",
    "    omega_reg2 = (1 + epsilon) * omega2 + (epsilon**2 / 2) * (omega_A2 + omega_B2)\n",
    "    omega_reg = np.sqrt(omega_reg2)\n",
    "\n",
    "    if print_stuff:\n",
    "        print('llr',llr,llr_split)\n",
    "        print('omega',omega2,omega_A2,omega_B2,np.sqrt(omega2),np.sqrt(omega_reg2))\n",
    "    if not compute_v:\n",
    "        return llr_reg,omega_reg,nobs \n",
    "        \n",
    "    V = compute_eigen2(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2) # If you want to try to bias-correct you can, this is optional\n",
    "    return llr_reg,omega_reg,V,nobs \n",
    "    \n",
    "\n",
    "def sw_test(ll1, grad1, hess1, params1,\n",
    "            ll2, grad2, hess2, params2, epsilon_auto=False, \n",
    "            epsilon=.5, alpha=0.05, biascorrect=False, ridge=1e-8):\n",
    "    \n",
    "    if epsilon_auto:\n",
    "        epsilon = compute_optimal_epsilon(ll1, grad1, hess1, params1,\n",
    "                 ll2, grad2, hess2, params2, ridge=ridge , alpha=alpha)\n",
    "        \n",
    "    llr_reg,omega_reg,V,nobs =  sw_test_stat(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=epsilon)\n",
    "    \n",
    "    if biascorrect:\n",
    "        llr_reg += V.sum() / 2\n",
    "\n",
    "    test_stat = llr_reg / (omega_reg * np.sqrt(nobs))\n",
    "\n",
    "    # Two-sided test\n",
    "    reject_high = (test_stat >= norm.ppf(1 - alpha / 2))\n",
    "    reject_low  = (test_stat <= norm.ppf(alpha / 2))\n",
    "    return int(reject_high) + 2 * int(reject_low)\n",
    "\n",
    "    \n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "\n",
    "\n",
    "reg_idx = regular_test(ll1, grad1, hess1, params1,\n",
    "            ll2, grad2, hess2, params2)\n",
    "\n",
    "\n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "reg_idx = sw_test(ll1, grad1, hess1, params1,ll2, grad2, hess2, params2, epsilon_auto=True, biascorrect=False, alpha=.05)\n",
    "print(reg_idx)\n",
    "\n",
    "yn,xn,nobs = gen_data3()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "reg_idx = sw_test(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2 , epsilon_auto=True, biascorrect=False, alpha=.05)\n",
    "print(reg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_distr(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2,\n",
    "                    epsilon=0.5, trials=500, seed=None, biascorrect=False):\n",
    "    nobs = ll1.shape[0]\n",
    "    #print('---------')\n",
    "    llr_reg, omega_reg, V, nobs = sw_test_stat(\n",
    "        ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=epsilon,print_stuff=False\n",
    "    )\n",
    "    if biascorrect:\n",
    "        llr_reg += V.sum() / 2\n",
    "    test_stat = llr_reg / (omega_reg * np.sqrt(nobs))\n",
    "    stat_dist = []\n",
    "\n",
    "    test_stat0 = (ll1-ll2).sum()/np.sqrt( nobs*(ll1-ll2).var() )\n",
    "    stats_s0 = []\n",
    "    \n",
    "    \n",
    "    for i in range(trials):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed + i)\n",
    "        sample = np.random.choice(np.arange(nobs), nobs, replace=True)\n",
    "        ll1_s = ll1[sample]\n",
    "        ll2_s = ll2[sample]\n",
    "\n",
    "        # Don't need V for bootstrap stats (saves computation)\n",
    "        llr_reg_s, omega_reg_s, nobs_in_s = sw_test_stat(\n",
    "            ll1_s, grad1, hess1, params1, ll2_s, grad2, hess2, params2, epsilon=epsilon, compute_v=False,print_stuff=False\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "        # bias correct V not directly available for bootstrap\n",
    "        stat_s = (llr_reg_s - llr_reg) / (omega_reg_s * np.sqrt(nobs_in_s))\n",
    "        stat_dist.append(stat_s)\n",
    "\n",
    "        ###### real stat for comparison...\n",
    "        llrs0 = ll1_s - ll2_s\n",
    "        stats_s0.append(  llrs0.sum()/  np.sqrt(nobs*llrs0.var()) )\n",
    "    if False:\n",
    "        print('test_stat0', nobs_in_s, nobs, (np.array(stats_s0)-test_stat0).mean(),np.array(stats_s0).mean(),test_stat0 )\n",
    "        print('test_stat', nobs_in_s, nobs, (np.array(stat_dist)-test_stat).mean(),np.array(stat_dist).mean(),test_stat )\n",
    "    #print('----')\n",
    "    return np.array(stat_dist), test_stat\n",
    "\n",
    "def sw_bs_test_helper(stat_dist, stat_obs, alpha=.05, left=True, right=True, print_stuff=False):\n",
    "    cv_upper = np.percentile(stat_dist, 100 * (1 - alpha / 2))\n",
    "    cv_lower = np.percentile(stat_dist, 100 * (alpha / 2))\n",
    "    if print_stuff:\n",
    "        print(f\"mean={stat_dist.mean():.3f}, cv_lower={cv_lower:.3f}, stat_obs={stat_obs:.3f}, cv_upper={cv_upper:.3f}\")\n",
    "    out = 0\n",
    "    if right and (stat_obs > cv_upper):\n",
    "        out = 1\n",
    "    if left and (stat_obs < cv_lower):\n",
    "        out += 2\n",
    "    return out\n",
    "\n",
    "def sw_bs_test(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2,\n",
    "               alpha=.05, trials=500, epsilon=0.5, biascorrect=False, seed=None, print_stuff=False):\n",
    "    stat_dist, test_stat = bootstrap_distr(\n",
    "        ll1, grad1, hess1, params1, ll2, grad2, hess2, params2,\n",
    "        epsilon=epsilon, trials=trials, seed=seed, biascorrect=biascorrect\n",
    "    )\n",
    "    return sw_bs_test_helper(stat_dist, test_stat, alpha=alpha, print_stuff=print_stuff)\n",
    "\n",
    "# Example Usage:\n",
    "# result = sw_bs_test(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=0.5, trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo2(total, gen_data, setup_shi, alpha=.05,  c1=.5,trials=500, biascorrect=False):\n",
    "    # Count for [model1, tie, model2] for each test\n",
    "    reg = np.zeros(3, dtype=int)\n",
    "    sw  = np.zeros(3, dtype=int)\n",
    "    swbs = np.zeros(3, dtype=int)\n",
    "\n",
    "    # Tracking statistics\n",
    "    llr_sum = 0.0\n",
    "    llr_sq_sum = 0.0\n",
    "    omega_sum = 0.0\n",
    "    nobs_last = None\n",
    "\n",
    "    for a in range(total):\n",
    "        np.random.seed()\n",
    "        yn, xn, nobs = gen_data()\n",
    "        ll1, grad1, hess1, params1, ll2, grad2, hess2, params2 = setup_shi(yn, xn)\n",
    "\n",
    "        # Update LLR-related stats\n",
    "        llrn = (ll1 - ll2).sum()\n",
    "        omegan = np.sqrt((ll1 - ll2).var())\n",
    "        llr_sum   += llrn\n",
    "        llr_sq_sum += llrn ** 2\n",
    "        omega_sum += omegan\n",
    "        nobs_last = nobs\n",
    "\n",
    "        # Run the tests\n",
    "        reg_idx = regular_test(\n",
    "            ll1, grad1, hess1, params1,\n",
    "            ll2, grad2, hess2, params2,\n",
    "            biascorrect=biascorrect, alpha=alpha\n",
    "        )\n",
    "        sw_idx = sw_test(\n",
    "            ll1, grad1, hess1, params1,\n",
    "            ll2, grad2, hess2, params2, epsilon = c1,\n",
    "            alpha=alpha, biascorrect=biascorrect\n",
    "        )\n",
    "        swbs_idx = sw_bs_test(\n",
    "            ll1, grad1, hess1, params1,\n",
    "            ll2, grad2, hess2, params2, epsilon = c1,\n",
    "            alpha=alpha, biascorrect=biascorrect, print_stuff=False\n",
    "        )\n",
    "\n",
    "        reg[reg_idx]   += 1\n",
    "        sw[sw_idx]     += 1\n",
    "        swbs[swbs_idx] += 1\n",
    "\n",
    "    # Convert counts to rates/frequencies\n",
    "    reg_freq = reg / total\n",
    "    sw_freq = sw / total\n",
    "    swbs_freq = swbs / total\n",
    "\n",
    "    llr_mean = llr_sum / total\n",
    "    llr_sd   = np.sqrt(llr_sq_sum / total - llr_mean ** 2)\n",
    "    omega_scaled = omega_sum * np.sqrt(nobs_last) / total if nobs_last is not None else np.nan\n",
    "\n",
    "    return reg_freq, sw_freq, swbs_freq, llr_mean, llr_sd, omega_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 0., 0.]), array([0.98, 0.01, 0.01]), array([0.81, 0.14, 0.05]), np.float64(9.814399238358282), np.float64(13.955164491623192), np.float64(18.400553192320118))\n"
     ]
    }
   ],
   "source": [
    "nobs = 250\n",
    "num_sims = 100\n",
    "c1 = .1\n",
    "setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn)\n",
    "\n",
    "gen_data_ex = lambda : gen_data(nobs=nobs,beta=0)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.62, 0.  , 0.38]), array([0.85, 0.01, 0.14]), array([0.8 , 0.02, 0.18]), np.float64(-20.590085591701705), np.float64(14.694959518661882), np.float64(22.29664477843189))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gen_data_ex = lambda : gen_data3(nobs=nobs,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.9 , 0.01, 0.09]), array([0.98, 0.  , 0.02]), array([0.85, 0.08, 0.07]), np.float64(17.981497754630468), np.float64(47.105923494471426), np.float64(45.260085299011706))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=nobs,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.94, 0.  , 0.06]), array([0.95, 0.  , 0.05]), array([0.87, 0.05, 0.08]), np.float64(6.097898222931017), np.float64(74.07236334666503), np.float64(79.7264837675732))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=1000,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.95, 0.  , 0.05]), array([0.96, 0.  , 0.04]), array([0.95, 0.  , 0.05]), np.float64(27.711071853057557), np.float64(113.03962887591918), np.float64(124.302611378288))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=nobs,beta=1.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.87, 0.  , 0.13]), array([0.94, 0.  , 0.06]), array([0.81, 0.06, 0.13]), np.float64(12.401679300735712), np.float64(58.77296769006161), np.float64(58.04286148624833))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=500,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# power 0.... need to see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 1.]), array([0., 0., 1.]), array([0.01, 0.  , 0.99]), np.float64(-269.02495977107816), np.float64(27.93332368576433), np.float64(34.03404945693487))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data3(nobs=nobs,beta=1.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 1.]), array([0., 0., 1.]), array([0., 0., 1.]), np.float64(-550.7235418581325), np.float64(35.69965689536537), np.float64(41.07290422187086))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data3(nobs=500,beta=1.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,trials=500,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
