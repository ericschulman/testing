{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import vuong_tests10 as vuong_tests_fast\n",
    "from vuong_test_base import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "class JointNormal1(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([params[0], 0.0], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "    \n",
    "    \n",
    "class JointNormal2(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([0.0, params[0]], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "\n",
    "\n",
    "def setup_shi(yn,xn):\n",
    "    # model 1 grad, etc.\n",
    "    nobs = yn.shape[0]\n",
    "    model1_param = np.array([yn.mean()])\n",
    "    model2_param = np.array([xn.mean()])\n",
    "    \n",
    "    model1_deriv = JointNormal1(yn,xn)\n",
    "    ll1 = model1_deriv.loglikeobs(model1_param)\n",
    "    grad1 =  model1_deriv.score_obs(model1_param).reshape( (nobs,1) )\n",
    "    hess1 = model1_deriv.hessian(model1_param)\n",
    "    \n",
    "    model2_deriv = JointNormal2(yn,xn)\n",
    "    ll2 = model2_deriv.loglikeobs(model2_param)\n",
    "    grad2 =  model2_deriv.score_obs(model2_param).reshape( (nobs,1) )  \n",
    "    hess2 = model2_deriv.hessian(model2_param)\n",
    "    \n",
    "    return ll1,grad1,hess1,model1_param,ll2,grad2,hess2,model2_param\n",
    "\n",
    "def gen_data(beta= 1.5, nobs=1000):\n",
    "    cov = [[25, 0], [0, 1]]\n",
    "    data = np.random.multivariate_normal([beta,beta], [[25,0],[0,1]],  nobs)\n",
    "    return data[:,0],data[:,1],nobs\n",
    "\n",
    "\n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "print(grad1.shape,hess1.shape)\n",
    "#NOTE! Weird size distortions with shi's test when theta = .5...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "def sw_test_stat(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=.5,compute_v=True,print_stuff=False):\n",
    "    nobs = ll1.shape[0]\n",
    "\n",
    "    idx_even = np.arange(0, nobs, 2)         # 0-based indices: 0,2,4,...\n",
    "    idx_odd  = np.arange(1, nobs, 2)         # 1,3,5,...\n",
    "\n",
    "    # Regular loglikelihood ratio statistic\n",
    "    llr = (ll1 - ll2).sum()\n",
    "    \n",
    "    # Split-sample difference statistic\n",
    "    llr_split = ll1[idx_even].sum() - ll2[idx_odd].sum()\n",
    "\n",
    "    # Regularized numerator (as in your expression)\n",
    "    llr_reg = llr + epsilon * llr_split\n",
    "\n",
    "    # Main variance\n",
    "    omega2 = (ll1 - ll2).var()\n",
    "    \n",
    "    # Split-group variances\n",
    "    omega_A2 = ll1[idx_even].var()\n",
    "    omega_B2 = ll2[idx_odd].var()\n",
    "\n",
    "    # Regularized variance\n",
    "    omega_reg2 = (1 + epsilon) * omega2 + (epsilon**2 / 2) * (omega_A2 + omega_B2)\n",
    "    omega_reg = np.sqrt(omega_reg2)\n",
    "\n",
    "    if print_stuff:\n",
    "        print('llr',llr,llr_split)\n",
    "        print('omega',omega2,omega_A2,omega_B2,np.sqrt(omega2),np.sqrt(omega_reg2))\n",
    "    if not compute_v:\n",
    "        return llr_reg,omega_reg,nobs \n",
    "        \n",
    "    V = compute_eigen2(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2) # If you want to try to bias-correct you can, this is optional\n",
    "    return llr_reg,omega_reg,V,nobs \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def sw_test(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=.5,\n",
    "            alpha=.05,  biascorrect=False):\n",
    "\n",
    "    llr_reg,omega_reg,V,nobs =  sw_test_stat(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=.5)\n",
    "\n",
    "    if biascorrect:\n",
    "        llr_reg += V.sum() / 2\n",
    "\n",
    "    test_stat = llr_reg / (omega_reg * np.sqrt(nobs))\n",
    "\n",
    "    # Two-sided test\n",
    "    reject_high = (test_stat >= norm.ppf(1 - alpha / 2))\n",
    "    reject_low  = (test_stat <= norm.ppf(alpha / 2))\n",
    "    return int(reject_high) + 2 * int(reject_low)\n",
    "\n",
    "    \n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "print(grad1.shape,hess1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_distr(setup_shi,yn, xn,\n",
    "                    epsilon=0.5, trials=500, seed=None, biascorrect=False):\n",
    "\n",
    "    ll1, grad1, hess1, params1, ll2, grad2, hess2, params2 = setup_shi(yn,xn)\n",
    "    nobs = ll1.shape[0]\n",
    "    #print('---------')\n",
    "    llr_reg, omega_reg, V, nobs = sw_test_stat(\n",
    "        ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=epsilon,print_stuff=False\n",
    "    )\n",
    "    if biascorrect:\n",
    "        llr_reg += V.sum() / 2\n",
    "    test_stat = llr_reg / (omega_reg * np.sqrt(nobs))\n",
    "    stat_dist = []\n",
    "\n",
    "    test_stat0 = (ll1-ll2).sum()/np.sqrt( nobs*(ll1-ll2).var() )\n",
    "    stats_s0 = []\n",
    "    \n",
    "    \n",
    "    for i in range(trials):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed + i)\n",
    "        sample = np.random.choice(np.arange(nobs), nobs, replace=True)\n",
    "        #print(sample.shape,nobs)\n",
    "        ll1_s, _, _, _, ll2_s, _, _, _ = setup_shi(yn[sample],xn[sample])\n",
    "        \n",
    "        #print('inner', ll1.mean(),ll2.mean(),ll1.var(),ll2.var())\n",
    "        #print(ll1_s.mean(),ll2_s.mean(),ll1_s.var(),ll2_s.var())\n",
    "        #print('------')\n",
    "        \n",
    "        # Don't need V for bootstrap stats (saves computation)\n",
    "        llr_reg_s, omega_reg_s, nobs_in_s = sw_test_stat(\n",
    "            ll1_s, grad1, hess1, params1, ll2_s, grad2, hess2, params2, epsilon=epsilon, compute_v=False,print_stuff=False\n",
    "        )\n",
    "\n",
    "        # bias correct V not directly available for bootstrap\n",
    "        stat_s = (llr_reg_s - llr_reg)/ (omega_reg_s * np.sqrt(nobs_in_s))\n",
    "        stat_dist.append(stat_s)\n",
    "\n",
    "        ###### real stat for comparison...\n",
    "        llrs0 = ll1_s - ll2_s\n",
    "        stats_s0.append(  llrs0.sum()/  np.sqrt(nobs*llrs0.var()) )\n",
    "    if False:\n",
    "        print('test_stat0', nobs_in_s, nobs, (np.array(stats_s0)-test_stat0).mean(),np.array(stats_s0).mean(),test_stat0 )\n",
    "        print('test_stat', nobs_in_s, nobs, (np.array(stat_dist)-test_stat).mean(),np.array(stat_dist).mean(),test_stat )\n",
    "    #print('----')\n",
    "    return np.array(stat_dist), test_stat\n",
    "\n",
    "def sw_bs_test_helper(stat_dist, stat_obs, alpha=.05, left=True, right=True, print_stuff=False):\n",
    "    cv_upper = np.percentile(stat_dist, 100 * (1 - alpha / 2))\n",
    "    cv_lower = np.percentile(stat_dist, 100 * (alpha / 2))\n",
    "    if print_stuff:\n",
    "        print(f\"mean={stat_dist.mean():.3f}, cv_lower={cv_lower:.3f}, stat_obs={stat_obs:.3f}, cv_upper={cv_upper:.3f}\")\n",
    "    out = 0\n",
    "    if right and (stat_obs > cv_upper):\n",
    "        out = 1\n",
    "    if left and (stat_obs < cv_lower):\n",
    "        out += 2\n",
    "    return out\n",
    "\n",
    "def sw_bs_test(setup_shi,yn, xn,\n",
    "               alpha=.05, trials=500, epsilon=0.5, biascorrect=False, seed=None, print_stuff=False):\n",
    "    stat_dist, test_stat = bootstrap_distr(setup_shi,yn, xn,\n",
    "        epsilon=epsilon, trials=trials, seed=seed, biascorrect=biascorrect\n",
    "    )\n",
    "    return sw_bs_test_helper(stat_dist, test_stat, alpha=alpha, print_stuff=print_stuff)\n",
    "\n",
    "# Example Usage:\n",
    "# result = sw_bs_test(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, epsilon=0.5, trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo2(total, gen_data, setup_shi, alpha=.05,  c1=.5,trials=100, biascorrect=False):\n",
    "    # Count for [model1, tie, model2] for each test\n",
    "    reg = np.zeros(3, dtype=int)\n",
    "    sw  = np.zeros(3, dtype=int)\n",
    "    swbs = np.zeros(3, dtype=int)\n",
    "\n",
    "    # Tracking statistics\n",
    "    llr_sum = 0.0\n",
    "    llr_sq_sum = 0.0\n",
    "    omega_sum = 0.0\n",
    "    nobs_last = None\n",
    "\n",
    "    for _ in range(total):\n",
    "        np.random.seed()\n",
    "        yn, xn, nobs = gen_data()\n",
    "\n",
    "        ll1, grad1, hess1, params1, ll2, grad2, hess2, params2 = setup_shi(yn, xn)\n",
    "        #print('outer', ll1.mean(),ll2.mean(),ll1.var(),ll2.var())\n",
    "        # Update LLR-related stats\n",
    "        llrn = (ll1 - ll2).sum()\n",
    "        omegan = np.sqrt((ll1 - ll2).var())\n",
    "        llr_sum   += llrn\n",
    "        llr_sq_sum += llrn ** 2\n",
    "        omega_sum += omegan\n",
    "        nobs_last = nobs\n",
    "\n",
    "        # Run the tests\n",
    "        reg_idx = regular_test(\n",
    "            ll1, grad1, hess1, params1,\n",
    "            ll2, grad2, hess2, params2,\n",
    "            biascorrect=biascorrect, alpha=alpha\n",
    "        )\n",
    "        sw_idx = sw_test(\n",
    "            ll1, grad1, hess1, params1,\n",
    "            ll2, grad2, hess2, params2, epsilon = c1,\n",
    "            alpha=alpha, biascorrect=biascorrect\n",
    "        )\n",
    "        swbs_idx = sw_bs_test(setup_shi,yn, xn, epsilon = c1, trials=trials,\n",
    "            alpha=alpha, biascorrect=biascorrect, print_stuff=False\n",
    "        )\n",
    "\n",
    "        reg[reg_idx]   += 1\n",
    "        sw[sw_idx]     += 1\n",
    "        swbs[swbs_idx] += 1\n",
    "\n",
    "    # Convert counts to rates/frequencies\n",
    "    reg_freq = reg / total\n",
    "    sw_freq = sw / total\n",
    "    swbs_freq = swbs / total\n",
    "\n",
    "    llr_mean = llr_sum / total\n",
    "    llr_sd   = np.sqrt(llr_sq_sum / total - llr_mean ** 2)\n",
    "    omega_scaled = omega_sum * np.sqrt(nobs_last) / total if nobs_last is not None else np.nan\n",
    "\n",
    "    return reg_freq, sw_freq, swbs_freq, llr_mean, llr_sd, omega_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1., 0., 0.]), array([0.97, 0.03, 0.  ]), array([0.71, 0.19, 0.1 ]), np.float64(11.242377920697999), np.float64(15.470319863054648), np.float64(19.498994354187612))\n"
     ]
    }
   ],
   "source": [
    "nobs = 250\n",
    "num_sims = 100\n",
    "c1 = .1\n",
    "setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn)\n",
    "\n",
    "gen_data_ex = lambda : gen_data(nobs=nobs,beta=0)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.66, 0.  , 0.34]), array([0.96, 0.01, 0.03]), array([0.72, 0.02, 0.26]), np.float64(-15.126555146091446), np.float64(23.211785552736224), np.float64(26.153026536645875))\n"
     ]
    }
   ],
   "source": [
    "def gen_data3(beta= 1.5, nobs=1000):\n",
    "    cov = [[25, 0], [0, 1]]\n",
    "    data = np.random.multivariate_normal([0,beta], [[25,0],[0,1]],  nobs)\n",
    "    return data[:,0],data[:,1],nobs\n",
    "\n",
    "gen_data_ex = lambda : gen_data3(nobs=nobs,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.91, 0.  , 0.09]), array([0.98, 0.01, 0.01]), array([0.84, 0.05, 0.11]), np.float64(14.35273073374017), np.float64(44.54203579384977), np.float64(43.177163468258875))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=nobs,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.96, 0.  , 0.04]), array([0.98, 0.  , 0.02]), array([0.76, 0.12, 0.12]), np.float64(19.532244040590232), np.float64(73.22089689345262), np.float64(83.93355990023429))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=1000,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.91, 0.01, 0.08]), array([0.95, 0.01, 0.04]), array([0.91, 0.04, 0.05]), np.float64(14.51251361738664), np.float64(134.32576672081944), np.float64(119.96502159834706))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=nobs,beta=1.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.9, 0. , 0.1]), array([0.96, 0.01, 0.03]), array([0.77, 0.01, 0.22]), np.float64(4.25046302315288), np.float64(51.076623981415544), np.float64(55.78736381794692))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data(nobs=500,beta=.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# power 0.... need to see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 1.]), array([0.42, 0.  , 0.58]), array([0.01, 0.  , 0.99]), np.float64(-272.34787956358224), np.float64(29.69547762585258), np.float64(33.71974272509288))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data3(nobs=nobs,beta=1.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 0., 1.]), array([0.08, 0.  , 0.92]), array([0., 0., 1.]), np.float64(-552.4352726597405), np.float64(37.950024791224614), np.float64(41.0193082167744))\n"
     ]
    }
   ],
   "source": [
    "gen_data_ex = lambda : gen_data3(nobs=500,beta=1.5)\n",
    "mc_out = monte_carlo2(num_sims,gen_data_ex,setup_shi_ex,c1=c1)\n",
    "print(mc_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
