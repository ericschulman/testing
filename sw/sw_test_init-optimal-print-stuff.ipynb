{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import vuong_tests10 as vuong_tests_fast\n",
    "from vuong_test_base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) (1, 1)\n"
     ]
    }
   ],
   "source": [
    "class JointNormal1(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([params[0], 0.0], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "    \n",
    "    \n",
    "class JointNormal2(GenericLikelihoodModel):\n",
    "    \n",
    "    def loglikeobs(self, params):\n",
    "        data = np.concatenate([[self.endog],self.exog.transpose()],axis=0)\n",
    "        mult_rv = stats.multivariate_normal([0.0, params[0]], [[1,0],[0,1]])\n",
    "        return mult_rv.logpdf(data.transpose())\n",
    "\n",
    "\n",
    "def setup_shi(yn,xn):\n",
    "    # model 1 grad, etc.\n",
    "    nobs = yn.shape[0]\n",
    "    model1_param = np.array([yn.mean()])\n",
    "    model2_param = np.array([xn.mean()])\n",
    "    \n",
    "    model1_deriv = JointNormal1(yn,xn)\n",
    "    ll1 = model1_deriv.loglikeobs(model1_param)\n",
    "    grad1 =  model1_deriv.score_obs(model1_param).reshape( (nobs,1) )\n",
    "    hess1 = model1_deriv.hessian(model1_param)\n",
    "    \n",
    "    \n",
    "    model2_deriv = JointNormal2(yn,xn)\n",
    "    ll2 = model2_deriv.loglikeobs(model2_param)\n",
    "    grad2 =  model2_deriv.score_obs(model2_param).reshape( (nobs,1) )  \n",
    "    hess2 = model2_deriv.hessian(model2_param)\n",
    "    \n",
    "    return ll1,grad1,hess1,model1_param,ll2,grad2,hess2,model2_param\n",
    "\n",
    "def gen_data(beta= 1.5, nobs=1000):\n",
    "    #np.random.seed(1)\n",
    "    cov = [[25, 0], [0, 1]]\n",
    "    data = np.random.multivariate_normal([beta,beta], [[25,0],[0,1]],  nobs)\n",
    "    return data[:,0],data[:,1],nobs\n",
    "\n",
    "def gen_data3(beta= 1.5, nobs=1000):\n",
    "    #np.random.seed(1)\n",
    "    cov = [[25, 0], [0, 1]]\n",
    "    data = np.random.multivariate_normal([0,beta], [[25,0],[0,1]],  nobs)\n",
    "    return data[:,0],data[:,1],nobs\n",
    "\n",
    "\n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "print(grad1.shape,hess1.shape)\n",
    "#NOTE! Weird size distortions with shi's test when theta = .5...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS_loglike(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, *args,ols=False, **kwargs):\n",
    "        super(OLS_loglike,self).__init__(*args,**kwargs)\n",
    "        self.ols = ols\n",
    "\n",
    "    def loglikeobs(self, params):\n",
    "        y = self.endog\n",
    "        x = self.exog\n",
    "        mu_y = np.matmul(x,params)  \n",
    "        resid = y - mu_y\n",
    "        sigma = np.sqrt(np.sum(resid**2)/resid.shape[0])\n",
    "        pr_y = stats.norm.logpdf( resid, loc=0,scale=sigma )\n",
    "        return pr_y\n",
    "\n",
    "\n",
    "def setup_shi2(yn,xn,return_model=False,num_params=4):\n",
    "    x1n,x2n = xn[:,0],xn[:,1:num_params+1]\n",
    "    \n",
    "    # model 1 grad, etc.\n",
    "    model1 = sm.OLS(yn,sm.add_constant(x1n))\n",
    "    model1_fit = model1.fit(disp=False)\n",
    "    params1 = (model1_fit.params)\n",
    "    \n",
    "    model1_deriv = OLS_loglike(yn,sm.add_constant(x1n))\n",
    "    ll1 = model1_deriv.loglikeobs(model1_fit.params)\n",
    "    grad1 =  model1_deriv.score_obs(model1_fit.params)    \n",
    "    hess1 = model1_deriv.hessian(model1_fit.params)\n",
    "    \n",
    "    #model 2 grad, etc.\n",
    "    model2 = sm.OLS(yn,sm.add_constant(x2n))\n",
    "    model2_fit = model2.fit(disp=False)\n",
    "    params2 = (model2_fit.params)\n",
    "    \n",
    "    model2_deriv = OLS_loglike(yn,sm.add_constant(x2n))\n",
    "    ll2 = model2_deriv.loglikeobs(model2_fit.params)\n",
    "    grad2 =  model2_deriv.score_obs(model2_fit.params)    \n",
    "    hess2 = model2_deriv.hessian(model2_fit.params)\n",
    "    \n",
    "    if return_model:\n",
    "        return ll1,grad1,hess1,params1,model1,ll2,grad2,hess2,params2,model2\n",
    "    return ll1,grad1,hess1,params1,ll2,grad2,hess2,params2\n",
    "\n",
    "\n",
    "def gen_data2(nobs=1000, a=0.25, num_params=4):\n",
    "    #np.random.seed(1)\n",
    "    x = np.random.normal(scale=1., size=(nobs,1+num_params))\n",
    "    e = np.random.normal(loc=0.0, scale=1.0, size=nobs)\n",
    "    y = 1 + a*x[:,0] + a/np.sqrt(num_params)*x[:,1:num_params+1].sum(axis=1) + e\n",
    "    return y,x,nobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Check variances and correlation of ll1 and ll2\n",
    "def check_ll_variances(ll1, ll2):\n",
    "    \"\"\"Checks variances, covariance, and correlation between ll1 and ll2,\n",
    "    as well as Var(ll1-ll2) identity.\"\"\"\n",
    "    var1 = float(np.var(ll1, ddof=0))\n",
    "    var2 = float(np.var(ll2, ddof=0))\n",
    "    cov12 = float(np.mean((ll1 - ll1.mean()) * (ll2 - ll2.mean())))\n",
    "    var_diff = float(np.var(ll1 - ll2, ddof=0))\n",
    "    rhs = var1 + var2 - 2.0 * cov12\n",
    "    corr = cov12 / (np.sqrt(var1) * np.sqrt(var2) + 1e-24)\n",
    "    print(\"---- ll variance/cov check ----\")\n",
    "    print(f\"Var(ll1)     = {var1:.6g}\")\n",
    "    print(f\"Var(ll2)     = {var2:.6g}\")\n",
    "    print(f\"Cov(ll1,ll2) = {cov12:.6g}, Corr = {corr:.6g}\")\n",
    "    print(f\"Var(ll1-ll2) = {var_diff:.6g}, Var(ll1)+Var(ll2)-2Cov = {rhs:.6g}\")\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "# 2. Variance identity check for your studentizer formula\n",
    "def check_variance_identity(ll1, ll2, epsilon):\n",
    "    \"\"\"Checks the correct identity for Var(√n · d̃):\n",
    "    0.5·Var(m_even) + 0.5·Var(m_odd) equals the paper's formula.\"\"\"\n",
    "    n = ll1.shape[0]\n",
    "    idx_even = np.arange(0, n, 2)\n",
    "    idx_odd  = np.arange(1, n, 2)\n",
    "    \n",
    "    # Group-specific contributions\n",
    "    m_even = (ll1[idx_even] - ll2[idx_even]) + epsilon * ll1[idx_even]\n",
    "    m_odd  = (ll1[idx_odd]  - ll2[idx_odd])  - epsilon * ll2[idx_odd]\n",
    "    \n",
    "    var_even = float(np.var(m_even, ddof=0)) if idx_even.size > 1 else 0.0\n",
    "    var_odd  = float(np.var(m_odd,  ddof=0)) if idx_odd.size  > 1 else 0.0\n",
    "    lhs = 0.5 * (var_even + var_odd)\n",
    "    \n",
    "    # Paper's formula\n",
    "    sigma2  = float(np.var(ll1 - ll2, ddof=0))\n",
    "    sigmaA2 = float(np.var(ll1[idx_even], ddof=0)) if idx_even.size > 1 else 0.0\n",
    "    sigmaB2 = float(np.var(ll2[idx_odd],  ddof=0)) if idx_odd.size  > 1 else 0.0\n",
    "    rhs = (1 + epsilon) * sigma2 + (epsilon**2 / 2.0) * (sigmaA2 + sigmaB2)\n",
    "    \n",
    "    print(\"---- variance identity check (correct) ----\")\n",
    "    print(f\"0.5·Var(m_even)+0.5·Var(m_odd) = {lhs:.6g}\")\n",
    "    print(f\"(1+eps)·Var(diff)+eps^2/2·(VarA+VarB) = {rhs:.6g}\")\n",
    "    print(f\"abs diff = {abs(lhs - rhs):.6g}\")\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "# 3. Sandwich H/V checks\n",
    "def hv_sanity(grad, hess, ridge=1e-8):\n",
    "    \"\"\"Check H condition number, eigenvalues, and trace(H^-1 V).\"\"\"\n",
    "    H = -np.mean(hess, axis=0)\n",
    "    H = 0.5*(H + H.T) + ridge * np.eye(H.shape[0])\n",
    "    V = (grad.T @ grad) / grad.shape[0]\n",
    "    V = 0.5*(V + V.T)\n",
    "    eigs = np.linalg.eigvalsh(H)\n",
    "    cond = np.linalg.cond(H)\n",
    "    trHinvV = float(np.trace(np.linalg.solve(H, V)))\n",
    "    print(\"---- H/V sanity ----\")\n",
    "    print(f\"H shape = {H.shape}, cond(H) = {cond:.3g}, eig min/max = {eigs.min():.6g}/{eigs.max():.6g}\")\n",
    "    print(f\"tr(H^-1 V) = {trHinvV:.6g}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "\n",
    "def hv_scale_diagnostics(grad, hess, ridge=1e-8, name=\"\"):\n",
    "    \"\"\"\n",
    "    Diagnose H,V scaling for either per-observation Hessians (n,p,p) or a single full-sample Hessian (p,p).\n",
    "    Prints eigen info and tr(H^{-1} V) for the two plausible scalings in the 2D case.\n",
    "    \"\"\"\n",
    "    n, p = grad.shape\n",
    "    \n",
    "    def sym(A): return 0.5 * (A + A.T)\n",
    "    \n",
    "    # V_hat: average score cross-product using log-likelihood scores\n",
    "    V_mean = sym((grad.T @ grad) / n)\n",
    "\n",
    "    # Single Hessian matrix: try both interpretations\n",
    "    H2        = sym(-hess)\n",
    "    H2_divn   = sym(-hess / n)\n",
    "\n",
    "    H2_r      = H2 + ridge * np.eye(p)\n",
    "    H2_divn_r = H2_divn + ridge * np.eye(p)\n",
    "\n",
    "    eig_2     = np.linalg.eigvalsh(H2_r)\n",
    "    eig_2divn = np.linalg.eigvalsh(H2_divn_r)\n",
    "\n",
    "    def tr_HinvV(H): return float(np.trace(np.linalg.solve(H, V_mean)))\n",
    "\n",
    "    tr2        = tr_HinvV(H2_r)\n",
    "    tr2_divn   = tr_HinvV(H2_divn_r)\n",
    "\n",
    "    print(\"Detected 2D Hessian; trying both scalings:\")\n",
    "    print(f\"H2 eig min/max       = {eig_2.min():.6g} / {eig_2.max():.6g}\")\n",
    "    print(f\"H2/n eig min/max     = {eig_2divn.min():.6g} / {eig_2divn.max():.6g}\")\n",
    "    print(f\"tr(H2^-1 V)          = {tr2:.6g}\")\n",
    "    print(f\"tr((H2/n)^-1 V)      = {tr2_divn:.6g}\")\n",
    "    print(\"Target magnitude for tr(H^{-1}V) ≈ parameter dimension p\")\n",
    "\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- ll variance/cov check ----\n",
      "Var(ll1)     = 328.319\n",
      "Var(ll2)     = 332.565\n",
      "Cov(ll1,ll2) = 329.95, Corr = 0.998533\n",
      "Var(ll1-ll2) = 0.983305, Var(ll1)+Var(ll2)-2Cov = 0.983305\n",
      "--------------------------------\n",
      "---- variance identity check (correct) ----\n",
      "0.5·Var(m_even)+0.5·Var(m_odd) = 83.8036\n",
      "(1+eps)·Var(diff)+eps^2/2·(VarA+VarB) = 84.0201\n",
      "abs diff = 0.216471\n",
      "-------------------------------------------\n",
      "Detected 2D Hessian; trying both scalings:\n",
      "H2 eig min/max       = 250 / 250\n",
      "H2/n eig min/max     = 1 / 1\n",
      "tr(H2^-1 V)          = 0.103648\n",
      "tr((H2/n)^-1 V)      = 25.912\n",
      "Target magnitude for tr(H^{-1}V) ≈ parameter dimension p\n",
      "Detected 2D Hessian; trying both scalings:\n",
      "H2 eig min/max       = 250 / 250\n",
      "H2/n eig min/max     = 1 / 1\n",
      "tr(H2^-1 V)          = 0.00450489\n",
      "tr((H2/n)^-1 V)      = 1.12622\n",
      "Target magnitude for tr(H^{-1}V) ≈ parameter dimension p\n",
      "---- H/V sanity ----\n",
      "H shape = (1, 1), cond(H) = 1, eig min/max = 250/250\n",
      "tr(H^-1 V) = 0.103648\n",
      "--------------------\n",
      "---- H/V sanity ----\n",
      "H shape = (1, 1), cond(H) = 1, eig min/max = 250/250\n",
      "tr(H^-1 V) = 0.00450489\n",
      "--------------------\n",
      "\n",
      "---- Diagnostic for Optimal Epsilon ----\n",
      "n = 250, alpha = 0.05, z = 1.9600\n",
      "sigma2 = 0.9833, sigmaA2 = 400, sigmaB2 = 260.3\n",
      "sigma = 0.9916, delta_star = -0.4166, phi_term = 0.02348\n",
      "diff_term = sigma2 - 2*(sigmaA2+sigmaB2) = -1320\n",
      "H1 cond = 1, H2 cond = 1\n",
      "tr(H1^(-1)V1) = 25.91, tr(H2^(-1)V2) = 1.126, tr_max = 25.91,denom_SD:18.17\n",
      "CPL_num = 549.8, denom_PL=3.9, phi_term=0.02348\n",
      "C_SD_hat = 0.1667, C_PL_hat = 3.311\n",
      "lnln_term = 1.709, eps_rate = 0.4763\n",
      "valid ratio = True, epsilon raw = 0.1759, clipped = 0.1759\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "---- Diagnostic for Optimal Epsilon ----\n",
      "n = 250, alpha = 0.05, z = 1.9600\n",
      "sigma2 = 0.1236, sigmaA2 = 0.6134, sigmaB2 = 0.3874\n",
      "sigma = 0.3516, delta_star = -0.1477, phi_term = 0.02348\n",
      "diff_term = sigma2 - 2*(sigmaA2+sigmaB2) = -1.878\n",
      "H1 cond = 1.3, H2 cond = 1.4\n",
      "tr(H1^(-1)V1) = 2.211, tr(H2^(-1)V2) = 5.163, tr_max = 5.163,denom_SD:0.7074\n",
      "CPL_num = 0.2775, denom_PL=0.1739, phi_term=0.02348\n",
      "C_SD_hat = 0.8531, C_PL_hat = 0.03747\n",
      "lnln_term = 1.709, eps_rate = 0.4763\n",
      "valid ratio = True, epsilon raw = 1.35, clipped = 1.35\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "---- Diagnostic for Optimal Epsilon ----\n",
      "n = 250, alpha = 0.05, z = 1.9600\n",
      "sigma2 = 3.214, sigmaA2 = 418.1, sigmaB2 = 345.1\n",
      "sigma = 1.793, delta_star = -0.7532, phi_term = 0.02348\n",
      "diff_term = sigma2 - 2*(sigmaA2+sigmaB2) = -1523\n",
      "H1 cond = 1, H2 cond = 1\n",
      "tr(H1^(-1)V1) = 25.98, tr(H2^(-1)V2) = 0.9932, tr_max = 25.98,denom_SD:19.54\n",
      "CPL_num = 1147, denom_PL=23.04, phi_term=0.02348\n",
      "C_SD_hat = 0.1554, C_PL_hat = 1.169\n",
      "lnln_term = 1.709, eps_rate = 0.4763\n",
      "valid ratio = True, epsilon raw = 0.2431, clipped = 0.2431\n",
      "----------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epsilon': 0.24309022778997746,\n",
       " 'n': 250,\n",
       " 'sigma2': 3.2136844993342235,\n",
       " 'sigmaA2': 418.12714735112735,\n",
       " 'sigmaB2': 345.1319707869925,\n",
       " 'sigma': np.float64(1.7926752353212847),\n",
       " 'delta_star': np.float64(-0.7531893692471859),\n",
       " 'phi_term': np.float64(0.023484710981724093),\n",
       " 'diff_term': -1523.3045517769056,\n",
       " 'tr1': 25.97620624253868,\n",
       " 'tr2': 0.9932060522868483,\n",
       " 'tr_max': 25.97620624253868,\n",
       " 'condH1': np.float64(1.0),\n",
       " 'condH2': np.float64(1.0),\n",
       " 'C_SD_hat': np.float64(0.1554291952283472),\n",
       " 'C_PL_hat': np.float64(1.1692605384799049),\n",
       " 'lnln_term': np.float64(1.7086424843059957),\n",
       " 'eps_rate': np.float64(0.4763144227414109),\n",
       " 'eps_unclipped': np.float64(0.24309022778997746),\n",
       " 'eps_clipped': 0.24309022778997746,\n",
       " 'valid': np.True_}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def _estimate_HV(grad, hess_total, ridge=1e-8):\n",
    "    \"\"\"\n",
    "    grad: (n,p) per-observation score of the log-likelihood\n",
    "    hess_total: (p,p) full-sample Hessian of the log-likelihood (sum over i)\n",
    "    Returns:\n",
    "    H_hat = -E[∂² log f]  (per-observation average curvature)\n",
    "    V_hat = E[s s′]       (uncentered score second moment)\n",
    "    \"\"\"\n",
    "    n = grad.shape[0]\n",
    "    H_hat = -hess_total / n\n",
    "    S = grad - grad.mean() # i think its supposed to be centered....\n",
    "    V_hat = (S.T @ S) / n\n",
    "    return H_hat, V_hat\n",
    "\n",
    "def _trace_HinvV(H, V):\n",
    "    return float(np.trace(np.linalg.solve(H, V)))\n",
    "\n",
    "\n",
    "def diagnostic_optimal_epsilon(\n",
    "    ll1, grad1, hess1, params1,\n",
    "    ll2, grad2, hess2, params2,\n",
    "    alpha=0.05, ridge=1e-8, min_epsilon=1e-6, max_epsilon=10.0,\n",
    "    floor_mult=None, enforce_positive_cpl=False, verbose=True\n",
    "):\n",
    "    nobs = ll1.shape[0]\n",
    "    idx_even = np.arange(0, nobs, 2)\n",
    "    idx_odd  = np.arange(1, nobs, 2)\n",
    "\n",
    "    # Per-sample variances\n",
    "    sigma2_hat   = float(np.var(ll1 - ll2, ddof=0))\n",
    "    sigmaA2_hat  = float(np.var(ll1[idx_even], ddof=0)) if idx_even.size > 1 else 0.0\n",
    "    sigmaB2_hat  = float(np.var(ll2[idx_odd],  ddof=0)) if idx_odd.size  > 1 else 0.0\n",
    "    sigma_hat    = np.sqrt(max(sigma2_hat, 1e-12))\n",
    "    diff_term    = sigma2_hat - 2.0*(sigmaA2_hat + sigmaB2_hat)\n",
    "\n",
    "    H1, V1 = _estimate_HV(grad1, hess1)\n",
    "    H2, V2 = _estimate_HV(grad2, hess2)\n",
    "    tr1 = abs(_trace_HinvV(H1, V1))\n",
    "    tr2 = abs(_trace_HinvV(H2, V2))\n",
    "    tr_max = max(tr1, tr2)\n",
    "\n",
    "    # Condition numbers for H1, H2\n",
    "    condH1 = np.linalg.cond(H1)\n",
    "    condH2 = np.linalg.cond(H2)\n",
    "\n",
    "    # Constants for formula\n",
    "    z = norm.ppf(1 - alpha/2.0)\n",
    "    phi_z = norm.pdf(z)\n",
    "    delta_star = (sigma_hat / 2.) * (z - np.sqrt(4. + z**2))\n",
    "    phi_arg = z - (delta_star / max(sigma_hat, 1e-12))\n",
    "    phi_term = norm.pdf(phi_arg)\n",
    "    denom_PL = 4. * (sigma_hat**3 + 1e-24)\n",
    "    denom_SD = np.sqrt(max((sigmaA2_hat + sigmaB2_hat)/2., 1e-24))\n",
    "\n",
    "    CPL_num = (abs(delta_star) * abs(diff_term) if enforce_positive_cpl\n",
    "               else delta_star * diff_term)\n",
    "    C_PL_hat = phi_term * CPL_num / denom_PL\n",
    "    C_SD_hat = 2. * phi_z * tr_max / denom_SD\n",
    "\n",
    "    # Log-log term for rate\n",
    "    lnln_term = max(np.log(np.log(max(nobs, 3))), 1e-6)\n",
    "    eps_rate = nobs**(-1/6.) * (lnln_term**(1/3.))\n",
    "\n",
    "    valid = np.isfinite(C_PL_hat) and np.isfinite(C_SD_hat) and (C_PL_hat > 0) and (C_SD_hat > 0)\n",
    "    if valid:\n",
    "        eps_unclipped = ((C_SD_hat / C_PL_hat) ** (1/3.)) * eps_rate\n",
    "    else:\n",
    "        eps_unclipped = eps_rate\n",
    "\n",
    "    # Optional rate-aware floor\n",
    "    if floor_mult is not None:\n",
    "        eps_unclipped = max(eps_unclipped, floor_mult * eps_rate)\n",
    "    eps_final = float(np.clip(eps_unclipped, min_epsilon, max_epsilon))\n",
    "\n",
    "    # Diagnostics print\n",
    "    if verbose:\n",
    "        print(\"\\n---- Diagnostic for Optimal Epsilon ----\")\n",
    "        print(f\"n = {nobs}, alpha = {alpha}, z = {z:.4f}\")\n",
    "        print(f\"sigma2 = {sigma2_hat:.4g}, sigmaA2 = {sigmaA2_hat:.4g}, sigmaB2 = {sigmaB2_hat:.4g}\")\n",
    "        print(f\"sigma = {sigma_hat:.4g}, delta_star = {delta_star:.4g}, phi_term = {phi_term:.4g}\")\n",
    "        print(f\"diff_term = sigma2 - 2*(sigmaA2+sigmaB2) = {diff_term:.4g}\")\n",
    "        print(f\"H1 cond = {condH1:.2g}, H2 cond = {condH2:.2g}\")\n",
    "        print(f\"tr(H1^(-1)V1) = {tr1:.4g}, tr(H2^(-1)V2) = {tr2:.4g}, tr_max = {tr_max:.4g},denom_SD:{denom_SD:.4g}\")\n",
    "        print(f\"CPL_num = {CPL_num:.4g}, denom_PL={denom_PL:.4g}, phi_term={phi_term:.4g}\")\n",
    "        print(f\"C_SD_hat = {C_SD_hat:.4g}, C_PL_hat = {C_PL_hat:.4g}\")\n",
    "        print(f\"lnln_term = {lnln_term:.4g}, eps_rate = {eps_rate:.4g}\")\n",
    "        print(f\"valid ratio = {valid}, epsilon raw = {eps_unclipped:.4g}, clipped = {eps_final:.4g}\")\n",
    "        print(\"----------------------------------------\\n\")\n",
    "\n",
    "    return {\n",
    "        \"epsilon\": eps_final,\n",
    "        \"n\": nobs,\n",
    "        \"sigma2\": sigma2_hat,\n",
    "        \"sigmaA2\": sigmaA2_hat,\n",
    "        \"sigmaB2\": sigmaB2_hat,\n",
    "        \"sigma\": sigma_hat,\n",
    "        \"delta_star\": delta_star,\n",
    "        \"phi_term\": phi_term,\n",
    "        \"diff_term\": diff_term,\n",
    "        \"tr1\": tr1,\n",
    "        \"tr2\": tr2,\n",
    "        \"tr_max\": tr_max,\n",
    "        \"condH1\": condH1,\n",
    "        \"condH2\": condH2,\n",
    "        \"C_SD_hat\": C_SD_hat,\n",
    "        \"C_PL_hat\": C_PL_hat,\n",
    "        \"lnln_term\": lnln_term,\n",
    "        \"eps_rate\": eps_rate,\n",
    "        \"eps_unclipped\": eps_unclipped,\n",
    "        \"eps_clipped\": eps_final,\n",
    "        \"valid\": valid\n",
    "    }\n",
    "\n",
    "yn,xn,nobs = gen_data(nobs=250,beta=0)\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "check_ll_variances(ll1, ll2)\n",
    "check_variance_identity(ll1, ll2, epsilon=0.5)  # or try your computed epsilon\n",
    "hv_scale_diagnostics(grad1, hess1, name=\"Model A\")\n",
    "hv_scale_diagnostics(grad2, hess2, name=\"Model B\")\n",
    "hv_sanity(grad1, hess1)\n",
    "hv_sanity(grad2, hess2)\n",
    "diagnostic_optimal_epsilon(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, alpha=0.05)\n",
    "\n",
    "yn,xn,nobs = gen_data2(nobs=250)\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi2(yn,xn)\n",
    "diagnostic_optimal_epsilon(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, alpha=0.05)\n",
    "\n",
    "yn,xn,nobs = gen_data3(nobs=250)\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn)\n",
    "diagnostic_optimal_epsilon(ll1, grad1, hess1, params1, ll2, grad2, hess2, params2, alpha=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
