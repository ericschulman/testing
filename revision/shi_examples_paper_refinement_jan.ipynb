{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import vuong_tests_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS_loglike(GenericLikelihoodModel):\n",
    "    \n",
    "    def __init__(self, *args,ols=False, **kwargs):\n",
    "        super(OLS_loglike,self).__init__(*args,**kwargs)\n",
    "        self.ols = ols\n",
    "\n",
    "    def loglikeobs(self, params):\n",
    "        y = self.endog\n",
    "        x = self.exog\n",
    "        mu_y = np.matmul(x,params)  \n",
    "        resid = y - mu_y\n",
    "        sigma = np.sqrt(np.sum(resid**2)/resid.shape[0])\n",
    "        pr_y = stats.norm.logpdf( resid, loc=0,scale=sigma )\n",
    "        return pr_y\n",
    "\n",
    "\n",
    "def setup_shi(yn,xn,return_model=False,num_params=4):\n",
    "    x1n,x2n = xn[:,0],xn[:,1:num_params+1]\n",
    "    \n",
    "    # model 1 grad, etc.\n",
    "    model1 = sm.OLS(yn,sm.add_constant(x1n))\n",
    "    model1_fit = model1.fit(disp=False)\n",
    "    params1 = (model1_fit.params)\n",
    "    \n",
    "    model1_deriv = OLS_loglike(yn,sm.add_constant(x1n))\n",
    "    ll1 = model1_deriv.loglikeobs(model1_fit.params)\n",
    "    grad1 =  model1_deriv.score_obs(model1_fit.params)    \n",
    "    hess1 = model1_deriv.hessian(model1_fit.params)\n",
    "    \n",
    "    #model 2 grad, etc.\n",
    "    model2 = sm.OLS(yn,sm.add_constant(x2n))\n",
    "    model2_fit = model2.fit(disp=False)\n",
    "    params2 = (model2_fit.params)\n",
    "    \n",
    "    model2_deriv = OLS_loglike(yn,sm.add_constant(x2n))\n",
    "    ll2 = model2_deriv.loglikeobs(model2_fit.params)\n",
    "    grad2 =  model2_deriv.score_obs(model2_fit.params)    \n",
    "    hess2 = model2_deriv.hessian(model2_fit.params)\n",
    "    \n",
    "    if return_model:\n",
    "        return ll1,grad1,hess1,params1,model1,ll2,grad2,hess2,params2,model2\n",
    "    return ll1,grad1,hess1,params1,ll2,grad2,hess2,params2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "def gen_data(nobs=1000, a=0.25, num_params=4):\n",
    "    x = np.random.normal(scale=1., size=(nobs,1+num_params))\n",
    "    e = np.random.normal(loc=0.0, scale=1.0, size=nobs)\n",
    "    y = 1 + a*x[:,0] + a/np.sqrt(num_params)*x[:,1:num_params+1].sum(axis=1) + e\n",
    "    return y,x,nobs\n",
    "\n",
    "yn,xn,nobs = gen_data()\n",
    "ll1,grad1,hess1,params1,ll2,grad2,hess2,params2 = setup_shi(yn,xn,return_model=False,num_params=15)\n",
    "print(grad1.shape,hess1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 200\n",
    "trials =1000\n",
    "\n",
    "skip_shi = True\n",
    "refinement_test=True\n",
    "adapt_c = False\n",
    "\n",
    "#calc_c =lambda nobs: (10*nobs**(1/4)/np.sqrt(nobs), .2*nobs**(1/3))\n",
    "#calc_c =lambda nobs: (.15*nobs**(1/4)/np.sqrt(nobs), .05*nobs**(1/3))\n",
    "calc_c =lambda nobs: (2/100*nobs**(1/4)/np.sqrt(nobs), 1/2000*nobs**(1/3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input arrays\n",
    "alpha = [0.01, 0.05, 0.10, 0.15]\n",
    "results = np.array([\n",
    "    [[0.98, 0.02, 0.00], [0.92, 0.08, 0.00]],\n",
    "    [[0.86, 0.14, 0.00], [0.66, 0.34, 0.00]],\n",
    "    [[0.66, 0.34, 0.00], [0.50, 0.50, 0.00]],\n",
    "    [[0.54, 0.46, 0.00], [0.41, 0.59, 0.00]]\n",
    "])\n",
    "# Column headers\n",
    "\n",
    "def print_mc2(alpha_levels ,test_results ):\n",
    "    table = \"\\\\begin{tabular}{c|cccc}\\n\"\n",
    "    table += \"\\\\hline\\n\"\n",
    "    table += \"\\\\textbf{$\\\\alpha$} & {} & \\\\textbf{No selection} & \\\\textbf{Model 1} & \\\\textbf{Model 2} \\\\\\\\\\n\"\n",
    "    table += \"\\\\hline\\n\"\n",
    "\n",
    "    for i in range(len(alpha_levels)):\n",
    "        alpha = alpha_levels[i]\n",
    "        table += \"{$%.2f$} & \\\\textbf{Normal} & %.2f & %.2f & %.2f \\\\\\\\\\n\" % (alpha, test_results[i][0][0], test_results[i][0][1], test_results[i][0][2])\n",
    "        table += \"& \\\\textbf{Bootstrap-ND} & %.2f & %.2f & %.2f \\\\\\\\\\n\" % (test_results[i][1][0], test_results[i][1][1], test_results[i][1][2])\n",
    "        table += \"\\\\hline\\n\"\n",
    "\n",
    "    table += \"\\\\end{tabular}\"\n",
    "\n",
    "    print(table)\n",
    "\n",
    "#print_mc2(alpha,results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evidence of power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1,a2 = np.sqrt(1.09-1), 0.00\n",
    "num_params= 9\n",
    "\n",
    "def gen_data2(nobs=1000, a1=np.sqrt(1.09-1), a2=0.00 , num_params=19):\n",
    "    x = np.random.normal(scale=1., size=(nobs,1+num_params))\n",
    "    e = np.random.normal(loc=0.0, scale=1.0, size=nobs)\n",
    "    y = 1 + a1*x[:,0] + a2/np.sqrt(num_params)*x[:,1:num_params+1].sum(axis=1) + e\n",
    "    return y,x,nobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cstar 64\n",
      "64 cstar 18.83913823192982\n",
      "64 cstar 18.83913823192982\n",
      "64 cstar 18.83913823192982\n",
      "0.005029733718731741\n"
     ]
    }
   ],
   "source": [
    "import vuong_tests5\n",
    "\n",
    "setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "gen_data_ex = lambda : gen_data2(nobs=nobs, a1=a1, a2=a2, num_params=num_params)\n",
    "\n",
    "res0 = vuong_tests5.monte_carlo(1,gen_data,setup_shi,trials=500,biascorrect=False)\n",
    "\n",
    "nobs=250\n",
    "a1,a2 = np.sqrt(1.09-1), 0.00\n",
    "c1,c2 = calc_c(nobs)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4,n=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cccc}\n",
      "\\hline\n",
      "\\textbf{$\\alpha$} & {} & \\textbf{No selection} & \\textbf{Model 1} & \\textbf{Model 2} \\\\\n",
      "\\hline\n",
      "{$0.01$} & \\textbf{Normal} & 0.89 & 0.12 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.86 & 0.14 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.05$} & \\textbf{Normal} & 0.60 & 0.40 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.62 & 0.38 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.10$} & \\textbf{Normal} & 0.45 & 0.55 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.48 & 0.52 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.15$} & \\textbf{Normal} & 0.31 & 0.69 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.33 & 0.68 & 0.00 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "num_params=4\n",
    "nobs=500\n",
    "a1,a2 = np.sqrt(1.09**.5-1), 0.00\n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data2(nobs=nobs, a1=a1, a2=a2, num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([refine_test,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4, n=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cccc}\n",
      "\\hline\n",
      "\\textbf{$\\alpha$} & {} & \\textbf{No selection} & \\textbf{Model 1} & \\textbf{Model 2} \\\\\n",
      "\\hline\n",
      "{$0.01$} & \\textbf{Normal} & 0.86 & 0.14 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.91 & 0.10 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.05$} & \\textbf{Normal} & 0.56 & 0.44 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.64 & 0.36 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.10$} & \\textbf{Normal} & 0.52 & 0.48 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.54 & 0.46 & 0.00 \\\\\n",
      "\\hline\n",
      "{$0.15$} & \\textbf{Normal} & 0.29 & 0.70 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.36 & 0.64 & 0.00 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "num_params=4\n",
    "nobs=250\n",
    "a1,a2 = np.sqrt(1.09-1), 0.00\n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data2(nobs=nobs, a1=a1, a2=a2, num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([reg,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# size stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4,n=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cccc}\n",
      "\\hline\n",
      "\\textbf{$\\alpha$} & {} & \\textbf{No selection} & \\textbf{Model 1} & \\textbf{Model 2} \\\\\n",
      "\\hline\n",
      "{$0.01$} & \\textbf{Normal} & 1.00 & 0.00 & 0.00 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.99 & 0.00 & 0.01 \\\\\n",
      "\\hline\n",
      "{$0.05$} & \\textbf{Normal} & 0.94 & 0.02 & 0.04 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.94 & 0.01 & 0.04 \\\\\n",
      "\\hline\n",
      "{$0.10$} & \\textbf{Normal} & 0.94 & 0.01 & 0.05 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.94 & 0.01 & 0.05 \\\\\n",
      "\\hline\n",
      "{$0.15$} & \\textbf{Normal} & 0.84 & 0.03 & 0.13 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.85 & 0.02 & 0.12 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "num_params=4\n",
    "nobs=250\n",
    "a=.25 \n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data(nobs=nobs, a=a,  num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([refine_test,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a  = .25, k= 4,n=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{c|cccc}\n",
      "\\hline\n",
      "\\textbf{$\\alpha$} & {} & \\textbf{No selection} & \\textbf{Model 1} & \\textbf{Model 2} \\\\\n",
      "\\hline\n",
      "{$0.01$} & \\textbf{Normal} & 0.98 & 0.01 & 0.01 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.98 & 0.01 & 0.01 \\\\\n",
      "\\hline\n",
      "{$0.05$} & \\textbf{Normal} & 0.97 & 0.01 & 0.03 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.96 & 0.01 & 0.03 \\\\\n",
      "\\hline\n",
      "{$0.10$} & \\textbf{Normal} & 0.85 & 0.04 & 0.10 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.87 & 0.04 & 0.10 \\\\\n",
      "\\hline\n",
      "{$0.15$} & \\textbf{Normal} & 0.81 & 0.04 & 0.14 \\\\\n",
      "& \\textbf{Bootstrap-ND} & 0.80 & 0.04 & 0.15 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "num_params=4\n",
    "nobs=500\n",
    "a=.25 \n",
    "c1,c2 = calc_c(nobs)\n",
    "alphas = [.01,.05,.1,.15]\n",
    "test_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    setup_shi_ex  = lambda yn,xn: setup_shi(yn,xn,num_params=num_params)\n",
    "    gen_data_ex = lambda : gen_data(nobs=nobs, a=a,  num_params=num_params)\n",
    "    mc_out = vuong_tests_fast.monte_carlo(num_sims,gen_data_ex,setup_shi,trials=trials,c1=c1,c2=c2,adapt_c=adapt_c,\n",
    "                                          skip_shi=skip_shi, refinement_test=refinement_test,alpha=alpha)\n",
    "    reg,twostep, refine_test, boot1,boot2,boot3,shi, llr,std, omega = mc_out\n",
    "    test_results.append([refine_test,boot3])\n",
    "print_mc2(alphas,np.array(test_results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
